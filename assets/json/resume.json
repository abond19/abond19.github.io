{"basics":{"name":"Andrew Bond","label":"PhD Student","image":"","email":"abond19@ku.edu.tr","url":"https://abond19.github.io","summary":"I am a PhD student in the Department of Computer Science and Engineering at Koc University. My research interests include deep generative models for videos, video representation learning, and mean-field analysis of machine learning algorithms."},"work":[{"name":"Adobe Research","position":"Research Scientist Intern","url":"https://research.adobe.com/","startDate":"2024-06","endDate":"2024-09","summary":"Worked in the Video AI lab with Jui-hsien Wang and Long Mai.","highlights":["Paper accepted to ICCV2025"]}],"volunteer":[],"education":[{"institution":"Koç University","location":"Istanbul, Turkey","url":"https://www.ku.edu.tr/","area":"Computer Science and Engineering","studyType":"PhD","startDate":"2023","endDate":"2028","courses":["Nonconvex Optimization for Machine Learning","Measure Theory","Cohomology on Manifolds","Digital Image and Video Processing"]},{"institution":"Koç University","location":"Istanbul, Turkey","url":"https://www.ku.edu.tr/","area":"Computer Engineering","studyType":"Bachelor","startDate":"2019","endDate":"2023","courses":["Deep Unsupervised Learning","Natural Language Processing","Computational Imaging","Intelligent User Interfaces","Real Analysis","Topology"],"GPA":3.55}],"awards":[{"title":"Outstanding TA Award","date":"2024-06","awarder":"Koç University Graduate School of Sciences and Engineering","url":"https://gsse.ku.edu.tr/en/","summary":"Awarded to the top TAs in the university during a semester."},{"title":"Dean's Honor List","date":"2023-01","awarder":"Koç University","url":"https://ku.edu.tr/en/","summary":"Awarded to students with over 3.5 GPA in a semester."},{"title":"Vehbi Koç Scholars","date":"4 times","awarder":"Koç University","url":"https://ku.edu.tr/en/","summary":"Awarded to students with outstanding GPA for a semester."}],"publications":[{"name":"TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360&deg; Panorama Generation","publisher":"ArXiv","releaseDate":"2025-06","url":"https://arxiv.org/pdf/2501.04782","summary":"Recent advances in image generation have led to remarkable improvements in synthesizing perspective images. However, these models still struggle with panoramic image generation due to unique challenges, including varying levels of geometric distortion and the requirement for seamless loop-consistency. To address these issues while leveraging the strengths of the existing models, we introduce TanDiT, a  method that synthesizes panoramic scenes by generating grids of tangent-plane images covering the entire 360&deg; view. Unlike previous methods relying on multiple diffusion branches, TanDiT utilizes a unified diffusion model trained to produce these tangent-plane images simultaneously within a single denoising iteration. Furthermore, we propose a model-agnostic post-processing step specifically designed to enhance global coherence across the generated panoramas. To accurately assess panoramic image quality, we also present two specialized metrics, TangentIS and TangentFID, and provide a comprehensive benchmark comprising captioned panoramic datasets and standardized evaluation scripts. Extensive experiments demonstrate that our method generalizes effectively beyond its training data, robustly interprets detailed and complex text prompts, and seamlessly integrates with various generative models to yield high-quality, diverse panoramic images."},{"name":"GaussianVideo: Efficient Video Representation via Hierarchical Gaussian Splatting","publisher":"ICCV 2025","releaseDate":"2025-01","url":"https://arxiv.org/pdf/2501.04782","summary":"Efficient neural representations for dynamic video scenes are critical for applications ranging from video compression to interactive simulations. Yet, existing methods often face challenges related to high memory usage, lengthy training times, and temporal consistency. To address these issues, we introduce a novel neural video representation that combines 3D Gaussian splatting with continuous camera motion modeling. By leveraging Neural ODEs, our approach learns smooth camera trajectories while maintaining an explicit 3D scene representation through Gaussians. Additionally, we introduce a spatiotemporal hierarchical learning strategy, progressively refining spatial and temporal features to enhance reconstruction quality and accelerate convergence. This memory-efficient approach achieves high-quality rendering at impressive speeds. Experimental results show that our hierarchical learning, combined with robust camera motion modeling, captures complex dynamic scenes with strong temporal consistency, achieving state-of-the-art performance across diverse video datasets in both high- and low-motion scenarios."},{"name":"Exploring the Precise Dynamics of Single-Layer GAN Models: Leveraging Multi-Feature Discriminators for High-Dimensional Subspace Learning","publisher":"NeurIPS 2024","releaseDate":"2024-11","url":"https://arxiv.org/pdf/2411.00498","summary":"Subspace learning is a critical endeavor in contemporary machine learning, particularly given the vast dimensions of modern datasets. In this study, we delve into the training dynamics of a single-layer GAN model from the perspective of subspace learning, framing these GANs as a novel approach to this fundamental task. Through a rigorous scaling limit analysis, we offer insights into the behavior of this model. Extending beyond prior research that primarily focused on sequential feature learning, we investigate the non-sequential scenario, emphasizing the pivotal role of inter-feature interactions in expediting training and enhancing performance, particularly with an uninformed initialization strategy. Our investigation encompasses both synthetic and real-world datasets, such as MNIST and Olivetti Faces, demonstrating the robustness and applicability of our findings to practical scenarios. By bridging our analysis to the realm of subspace learning, we systematically compare the efficacy of GAN-based methods against conventional approaches, both theoretically and empirically. Notably, our results unveil that while all methodologies successfully capture the underlying subspace, GANs exhibit a remarkable capability to acquire a more informative basis, owing to their intrinsic ability to generate new data samples. This elucidates the unique advantage of GAN-based approaches in subspace learning tasks."},{"name":"GECTurk: Grammatical Error Correction and Detection Dataset for Turkish","publisher":"Findings of IJCNLP-AACL 2023","releaseDate":"2023-09","url":"https://arxiv.org/pdf/2309.11346","summary":"Grammatical Error Detection and Correction (GEC) tools have proven useful for native speakers and second language learners. Developing such tools requires a large amount of parallel, annotated data, which is unavailable for most languages. Synthetic data generation is a common practice to overcome the scarcity of such data. However, it is not straightforward for morphologically rich languages like Turkish due to complex writing rules that require phonological, morphological, and syntactic information. In this work, we present a flexible and extensible synthetic data generation pipeline for Turkish covering more than 20 expert-curated grammar and spelling rules (a.k.a., writing rules) implemented through complex transformation functions. Using this pipeline, we derive 130,000 high-quality parallel sentences from professionally edited articles. Additionally, we create a more realistic test set by manually annotating a set of movie reviews. We implement three baselines formulating the task as i) neural machine translation, ii) sequence tagging, and iii) prefix tuning with a pretrained decoder-only model, achieving strong results. Furthermore, we perform exhaustive experiments on out-of-domain datasets to gain insights on the transferability and robustness of the proposed approaches. Our results suggest that our corpus, GECTurk, is high-quality and allows knowledge transfer for the out-of-domain setting. To encourage further research on Turkish GEC, we release our datasets, baseline models, and the synthetic data generation pipeline at https://github.com/GGLAB-KU/gecturk."},{"name":"VidStyleODE: Disentangled Video Editing via StyleGAN and NeuralODEs","publisher":"ICCV 2023","releaseDate":"2023-06","url":"https://openaccess.thecvf.com/content/ICCV2023/papers/Ali_VidStyleODE_Disentangled_Video_Editing_via_StyleGAN_and_NeuralODEs_ICCV_2023_paper.pdf","summary":"We propose VidStyleODE , a spatiotemporally continuous disentangled video representation based upon StyleGAN and Neural-ODEs. Effective traversal of the latent space learned by Generative Adversarial Networks (GANs) has been the basis for recent breakthroughs in image editing. However, the applicability of such advancements to the video domain has been hindered by the difficulty of representing and controlling videos in the latent space of GANs. In particular, videos are composed of content (i.e., appearance) and complex motion components that require a special mechanism to disentangle and control. To achieve this, VidStyleODE encodes the video content in a pre-trained StyleGAN W+ space and benefits from a latent ODE component to summarize the spatiotemporal dynamics of the input video. Our novel continuous video generation process then combines the two to generate high-quality and temporally consistent videos with varying frame rates. We show that our proposed method enables a variety of applications on real videos: text-guided appearance manipulation, motion manipulation, image animation, and video interpolation and extrapolation. Project website: https://cyberiada.github.io/VidStyleODE."}],"skills":[{"name":"Deep Learning","level":"Master","icon":"fa-solid fa-hashtag","keywords":["GANs","Diffusion Models","Multimodal LLMs","Gaussian Splatting","Neural ODEs","Mean-Field Analysis"]}],"languages":[{"language":"English","fluency":"Fluent","icon":""}],"expertise":[{"name":"Deep Learning","icon":"fa-solid fa-tag","keywords":["GANs","Diffusion Models","Multimodal LLMs","Gaussian Splatting","Neural ODEs","Video Representation Learning","Mean-Field Analysis"]},{"name":"Mathematics","icon":"fa-solid fa-tag","keywords":["Measure Theory","Propagation of Chaos","Convergence of Probability Measures","Stochastic Processes","Stochastic Differential Equations","Topology and Differential Geometry","Functional Analysis","Operator Theory","Abstract Algebra"]}],"projects":[{"name":"VidStyleODE","summary":"","highlights":["Video Generation","Video Editing","GANs","Neural ODEs"],"startDate":"2022-09","endDate":"2023-06","url":"https://cyberiada.github.io/VidStyleODE/"}]}